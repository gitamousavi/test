Deep Learning Is Effective for Classifying Normal versus Age-Related Macular Degeneration Optical Coherence Tomography Images

Abstract
Objective: The advent of Electronic Medical Records (EMR) with large electronic imaging databases along with advances in deep neural networks with machine learning has provided a unique opportunity to achieve milestones in automated image analysis. Optical coherence tomography (OCT) is the most commonly obtained imaging modality in ophthalmology and represents a dense and rich dataset when combined with labels derived from the EMR. We sought to determine if deep learning could be utilized to distinguish normal OCT images from images from patients with Age-related Macular Degeneration (AMD). Design: EMR and OCT database study. Subjects: Normal and AMD patients who had a macular OCT. Methods: Automated extraction of an OCT imaging database was performed and linked to clinical endpoints from the EMR. OCT macula scans were obtained by Heidelberg Spectralis, and each OCT scan was linked to EMR clinical endpoints extracted from EPIC. The central 11 images were selected from each OCT scan of two cohorts of patients: normal and AMD. Cross-validation was performed using a random subset of patients. Receiver operator curves (ROC) were constructed at an independent image level, macular OCT level, and patient level. Main outcome measure: Area under the ROC. Results: Of a recent extraction of 2.6 million OCT images linked to clinical datapoints from the EMR, 52,690 normal macular OCT images and 48,312 AMD macular OCT images were selected. A deep neural network was trained to categorize images as either normal or AMD. At the image level, we achieved an area under the ROC of 92.78% with an accuracy of 87.63%. At the macula level, we achieved an area under the ROC of 93.83% with an accuracy of 88.98%. At a patient level, we achieved an area under the ROC of 97.45% with an accuracy of 93.45%. Peak sensitivity and specificity with optimal cutoffs were 92.64% and 93.69% respectively. Conclusions: Deep learning techniques achieve high accuracy and is effective as a new image classification technique. These findings have important implications in utilizing OCT in automated screening and the development of computer aided diagnosis tools in the future.


Purpose: The advent of electronic medical records (EMRs) with large electronic imaging databases alongwith advances in deep neural networks with machine learning has provided a unique opportunity to achievemilestones in automated image analysis. Optical coherence tomography (OCT) is the most common imagingmodality in ophthalmology and represents a dense and rich data set when combined with labels derived from theEMR. We sought to determine whether deep learning could be utilized to distinguish normal OCT images fromimages from patients with age-related macular degeneration (AMD).Design: EMR and OCT database study.Subjects: Normal and AMD patients who underwent macular OCT.Methods: Automated extraction of an OCT database was performed and linked to clinical end points fromthe EMR. Optical coherence tomography scans of the macula were obtained by Heidelberg Spectralis, and eachOCT scan was linked to EMR clinical end points extracted from EPIC. The central 11 images were selected fromeach OCT scan of 2 cohorts of patients: normal and AMD. Cross-validation was performed using a randomsubset of patients. Receiver operating characteristic (ROC) curves were constructed at an independent imagelevel, macular OCT level, and patient level.Main Outcome Measure: Area under the ROC curve.Results: Of a recent extraction of 2.6 million OCT images linked to clinical data points from the EMR, 52 690normal macular OCT images and 48 312 AMD macular OCT images were selected. A deep neural network wastrained to categorize images as either normal or AMD. At the image level, we achieved an area under the ROC curveof 92.78% with an accuracy of 87.63%. At the macula level, we achieved an area under the ROC curve of 93.83%with an accuracy of 88.98%. At a patient level, we achieved an area under the ROC curve of 97.45% with an ac-curacy of 93.45%. Peak sensitivity and speciﬁcity with optimal cutoffs were 92.64% and 93.69%, respectively.Conclusions: The deep learning technique achieves high accuracy and is effective as a new image classi-ﬁcation technique. These ﬁndings have important implications in utilizing OCT in automated screening and thedevelopment of computer-aided diagnosis tools in the future.

Optical coherence tomography (OCT) has become the mostcommonly used imaging modality in ophthalmology, with4.39 million, 4.93 million, and 5.35 million OCTs per-formed in 2012, 2013, and 2014, respectively, in the U.S.Medicare population.1Since its development in 1991,2a70-fold increase in OCT use for diagnosing age-relatedmacular degeneration (AMD) was reported between 2002and 2009.3Furthermore, since the development ofantiangiogenic agents, OCT has become a critical tool forbaseline retinal evaluation before initiation of therapy andmonitoring therapeutic effect.4,5This increase in the useof OCT, with images stored in large electronic databases,highlights the ever-increasing time and effort spent byproviders interpreting images.The key OCT ﬁndings in AMD, including drusen, retinalpigment epithelium changes, and subretinal and intraretinalﬂuid,4share some common OCT features that aredistinctively different from a normal retina.6Correctidentiﬁcation of these characteristics allows for precisemanagement of neovascular AMD and guides the decisionof whether intravitreal therapy with antievascularendothelial growth factor agents should be given ornot.7e9Computer-aided diagnosis (CAD) has the potentialfor allowing more efﬁcient identiﬁcation of pathologic OCTimages and directing the attention of the clinician to regionsof interest on the OCT images.The concept of CAD is not novel and has been appliedin radiology, a ﬁeld where the increasing demand ofimaging studies has begun to outpace the capacity ofpracticing radiologists.10A number of CAD systemshave been approved by the US Food and DrugAdministration for lesion detection and volumetric analysis in mammography, chest radiography, and chestcomputed tomography.11Traditional image analysis required the manual devel-opment of convolutional matrices applied to an image foredge detection and feature extraction. In addition, priorwork on OCT image classiﬁcation of diseases has relied onmachine learning techniques such as principal componentanalysis, support vector machine, and random forest.12e14However, there has recently been a revolutionary step for-ward in machine learning techniques with the advent ofdeep learning, where a many-layered neural network istrained to develop these convolutional matrices purely fromtraining data.15Speciﬁcally, the development ofconvolutional neural network layers allowed for signiﬁcantgains in the ability to classify images and detect objects ina picture.16e18Within ophthalmology, deep learning hasbeen recently applied at a limited capacity to automateddetection of diabetic retinopathy from fundus photographs,visual ﬁeld perimetry in glaucoma patients, grading ofnuclear cataracts, and segmentation of foveal microvascu-lature, each with promising initial ﬁndings.19e22Although deep learning has revolutionized the ﬁeld ofcomputer vision, its application is usually limited due tothe lack of large training sets. Often several tens ofthousands of examples are required before deep learningcanbeusedeffectively.Withtheever-increasinguseofOCT as an imaging modality in ophthalmology along withthe use of codiﬁed structured clinical data in the electronicmedical record (EMR), we sought to link 2 large data setstogether to use as a training set for developing a deeplearning algorithm to distinguish AMD from normal OCTimages.

Methods
This study was approved by the Institutional Review Board of theUniversity of Washington (UW) and adhered to the tenets of theDeclaration of Helsinki and the Health Insurance Portability andAccountability Act.Optical Coherence Tomography and ElectronicMedical Record ExtractionMacular OCT scans from 2006 to 2016 were extracted using anautomated extraction tool from the Heidelberg Spectralis (Heidel-berg Engineering, Heidelberg, Germany) imaging database. Eachmacular scan was obtained using a 61-line raster macula scan, andevery image of each macular OCT was extracted. The images werethen linked by patient medical record number and dates to theclinical data stored in EPIC. Speciﬁcally, all clinical diagnoses andthe dates of every clinical encounter, macular laser procedure, andintravitreal injection were extracted from the EPIC Clarity tables.Patient and Image SelectionA normal patient was deﬁned as having no retinal InternationalClassiﬁcation of Diseases, 9th Revision (ICD-9) diagnosis andbetter than 20/30 vision in both eyes during the entirety of theirrecorded clinical history at UW. An AMD patient was deﬁned ashaving an ICD-9 diagnosis of AMD (codes 362.50, 362.51, and362.52) by a retina specialist, at least 1 intravitreal injection ineither eye, and worse than 20/30 vision in the better-seeing eye.
Patients with other macular pathology by ICD-9 code wereexcluded. These parameters were chosen a priori to ensure thatmacular pathology was most likely present in both eyes in theAMD patients and absent in both eyes in the normal patients.Consecutive images of patients meeting these criteria wereincluded, and no images were excluded due to image quality.Labels from the EMR were then linked to the OCT macular im-ages, and the data were stripped of all protected health identiﬁers.As most of the macular pathology is concentrated in the fovealregion, the decision was made a priori to select the central 11images from each macular OCT set, and each image was thentreated independently, labeled as either normal or AMD. Theimages were histogram equalized and the resolution downsampledto 192 124 pixels due to limitations of memory. The image setwas then divided into 2 sets, with 20% of the patients in eachgroup placed into the validation set; the rest were used for training.Care was taken to ensure that the validation set and the training setcontained images from a mutually exclusive group of patients (ie,no single patient contributed images to both the training andvalidation sets). The order of images was then randomized in thetraining set.

Deep Learning Classiﬁcation ModelA modiﬁed version of the VGG16 convolutional neural network23was used as the deep learning model for classiﬁcation (Fig 1).Weights were initialized using the Xavier algorithm.24Trainingwas then performed using multiple iterations, each with a batchsize of 100 images, with a starting learning rate of 0.001 withstochastic gradient descent optimization. At each iteration, theloss of the model was recorded; at every 500 iterations, theperformance of the neural network was assessed using cross-validation with the validation set. The training was stopped whenthe loss of the model decreased and the accuracy of the validationset decreased.An occlusion test17was performed to identify the areascontributing most to the neural network’s assigning the categoryof AMD. A blank 20 20-pixel box was systematically movedacross every possible position in the image and the probabilitieswere recorded. The highest drop in the probability represents theregion of interest that contributed the highest importance to thedeep learning algorithm.Caffe (http://caffe.berkeleyvision.org/) and Python (http://www.python.org) were used to perform deep learning. All trainingoccurred using the NVIDIA Pascal Titan X graphics processingunit with NVIDA cuda (version 8.0) and cu-dnn (version 5.5.1)libraries (http://www.nvidia.com). Macular OCTelevel analysiswas performed by averaging the probabilities of the images ob-tained from the same macular OCT. Patient-level analysis wasperformed by averaging the probabilities of the images obtainedfrom the same patient. Receiver operating characteristic (ROC)curves were constructed using the probability output from the deeplearning model. Statistics were performed using R 

ResultsWe successfully extracted 2.6 million OCT images of 43 328macular OCT scans from 9285 patients. After linking the macularOCT scans to the EMR, 48 312 images from 4392 normal OCTscans and 52 690 images from 4790 AMD OCT scans wereselected. A total of 80 839 images (41 074 from AMD, 39 765from normal) were used for training and 20 163 images (11 616from AMD, 8547 from normal) were used for validation (Table 1).After 8000 iterations of training the deep learning model, thetraining was stopped due to overﬁtting occurring after that point(Fig 2). ROC curves are shown at the image level, OCT macularlevel, and patient level in Figure 3. The average time to evaluatea single image after training was complete was 4.97 ms.At the level of each individual image, we achieved an accuracyof 87.63% with a sensitivity of 84.63% and a speciﬁcity of 91.54%. After constructing an ROC curve, the peak sensitivity and speci-ﬁcity with optimal cutoffs were 87.08% and 87.05%, respectively.The area under the ROC curve (AUROC) was 92.77%.By grouping the images in the same OCT scan and averagingthe probabilities from each image, we achieved an accuracy of88.98% with a sensitivity of 85.41% and a speciﬁcity of 93.82%.After constructing the ROC curve, the peak sensitivity and speci-ﬁcity with optimal cutoffs were 88.63% and 87.77%, respectively.The AUROC was 93.82%.By averaging the probabilities from each image from thesame patient, we achieved an accuracy of 93.45% with asensitivity of 83.82% and a speciﬁcity of 96.40%. After con-structing the ROC curve, the peak sensitivity and speciﬁcity withoptimal cutoffs were 92.64% and 93.69%, respectively. TheAUROC was 97.46%.Example images from the occlusion test, shown in Figure 4,demonstrate that the neural network was successfully able toidentify pathologic regions on the OCT. These areas representthe area in each image most critical to the trained network incategorizing the image as AMD.

